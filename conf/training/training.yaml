# Data and logging
model_weights: "results/best_model_delta_t_0.01.pth"
training_dir: "/mnt/jonathan/DataFlowMatching/small_training_data" #"/mnt/justin/training_data/" # #  "/mnt/justin/small_data/"  
log_dir: "log/"

# General parameters
num_epochs: 1000
batch_size: 1


max_points: 150
time_step: 5e-2
load_model: False

cont: False 
model_checkpoint: null 
test: False 
hparams: null 

# Losses 
pair_loss: False
recon_loss: True 
consistency_loss: True 
feature_var_loss: True 

sparse_loss: False
data_augment: True #False  

sparsity_weight: 0.0
recon_weight: 0.4
consistency_weight: 0.4
barlow_weight: 0.0
feature_var_weight: 0.2
denoise_input: False

# Barlow
barlow_lambda: 1e-6

# Consistency augmentation
num_lowres_augmentations: 16
min_radius: 0.01
max_radius: 0.2
svm_batch_size: 4 # 2048 PC. do the max RAM allows since not used for gradients + batches are to be accumulated...

# Variance regularization
target_variance: 0.1
max_reg_loss: 20

# SVM representation
#max_pool_only: False 
#mean_pool_only: True
#sum_max_mean: False
#concat_max_mean: False 