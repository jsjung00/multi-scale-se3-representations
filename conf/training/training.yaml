# Data and logging
training_dir: "/mnt/jonathan/DataFlowMatching/small_training_data" #"/mnt/justin/training_data/" # #  "/mnt/justin/small_data/"  
log_dir: "log/"
experiment_name: "some_experiment"
checkpoint_dir: "/mnt/justin/multi-scale-se3-representations/checkpoints/test_folder"

enable_tqdm: True #False #  
early_stopping: False #True


# General parameters
num_epochs: 10000 
batch_size: 6


max_points: 150
time_step: 5e-2
load_model: False

cont: False #False 
model_checkpoint: #null 
test: False 
hparams: null 

# Losses 
pair_loss: False
recon_loss: True 
consistency_loss: True 
feature_var_loss: False

sparse_loss: False
data_augment: True #False  

sparsity_weight: 0.0
recon_weight: 0.5
consistency_weight: 0.5
barlow_weight: 0.0
feature_var_weight: 0.
denoise_input: False

# Barlow
barlow_lambda: 1e-6

# Consistency augmentation
num_lowres_augmentations: 6
min_radius: 0.002
max_radius: 0.05
svm_batch_size: 8 # 2048 PC. do the max RAM allows since not used for gradients + batches are to be accumulated...
all_res_start: False # If true, randomly pick some x_t to be the highest resolution and create lower res versions from that. 

# Variance regularization
target_variance: 0.1
max_reg_loss: 10

# SVM representation
#max_pool_only: False 
#mean_pool_only: True
#sum_max_mean: False
#concat_max_mean: False 